# -*- coding: utf-8 -*-
"""WordCloud and Word Frequencies.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XXsnMMjdrdMFGTanRnznQcYpuX-GQP2F

Project Gutenberg is zealously noncommercial, digitizes books in the public domain alone, and publishes an accurate rendition of the full electronic text (but not the formatting). The Million Book Project, Internet Archives, and Open Content Alliance are noncommercial, target public-domain books, but also aspire to process copyrighted “orphan” books, and show users page images backed up by full-text searching.

In this task,we are going to use two books with titles for our analysis of the popular books and plot the top 30 used words. The two books are:
- Pride and Prejudice
- Twelve Years a Slave

When sorting the word frequencies we do it in descending order, to specify the tuple element we use the itemgetter function-operator module.

### Importing the necessary modules.
"""

# Commented out IPython magic to ensure Python compatibility.
from operator import itemgetter
import matplotlib.pyplot as plt
# %matplotlib inline
import nltk
nltk.download('punkt')
nltk.download('stopwords')

"""### Loading the data"""

from pathlib import Path

from textblob import TextBlob

"""### Lets get started with the first book-Pride and Prejudice"""

blob= TextBlob(Path('Pride and Prejudice.txt').read_text())

from nltk.corpus import stopwords

"""Let us get the frequencies of the words"""

items=blob.word_counts.items()

stop_words=stopwords.words('english')

"""Let us now eliminate the stop words"""

items =[item for item in items if item[0] not in stop_words]

"""### Sorting the Words Frequency"""

sorted_items=sorted(items, key=itemgetter(1), reverse=True)

sorted_items[len(sorted_items)-1]

len(sorted_items)

top30=sorted_items[:30]

sorted_items[0]

"""### Convert to dataframe"""

import pandas as pd

df=pd.DataFrame(top30, columns=['words','count'])

df

axes=df.plot.bar(x='words',y='count', legend=False)

"""The bar plot above consists of the 30 top most used words. And the names have been plot against to the number of times the words have been used in the novel. The leading is " while the least used word is lady

### Visualizing the Word Frequencies with Word Cloud

A word cloud (or tag cloud) is a word visualization that displays the most used words in a text from small to large, according to how often each appears.

They give a glance into the most important keywords in news articles, social media posts, and customer reviews, among other text. They can also provide interesting insights when comparing two texts against each other, like political speeches or product reviews.

In this case, we are creating our word clouds using the top 30 words in the novel Pride and Prejudice

### Loading the data
"""

text = Path('Pride and Prejudice.txt').read_text()

text

"""- We load the mask image that specifies the word cloud's shape
- The WordCloud fills non-white areas of a mask image with the text
- Load the mask filling using the imread function from imageio module found in Anaconda
"""

import imageio

mask_image=imageio.imread('mask_heart.png')

"""- Configuring the WordCloud Object
- 400 by 200 pixels - default image size
- Colors used are assigned randomly - from the color map

"""

from wordcloud import WordCloud

wordcloud =WordCloud(width=1000,height=1000,colormap='prism',mask=mask_image,background_color='white')

"""- WordCloud has a method called generate() 
- receives the text as an argument ad creates the word cloud
"""

wordcloud=wordcloud.generate(text)

"""- Removes the stop words, from the text argument using the inbuilt stop word list 
- Calculates word frequnces for the remaing words 
- Builds the cloud with maximum 200 by default -> max-words

Saving the image
"""

wordcloud=wordcloud.to_file('PrideandPrejudiceHeart.png')

plt.imshow(wordcloud)

"""The diagram above is a representation of a word cloud. The bigger the size of the word the higher the frequency of the word being used and the smaller the word then the frequently the word has been used.

### Now lets move on to the next book- Twelve Years a Slave

We are going to repeat the same procedure as the first book
"""

blob = TextBlob(Path('Twelve Years a Slave.txt').read_text())

items=blob.word_counts.items()

stop_words=stopwords.words('english')

items =[item for item in items if item[0] not in stop_words]

sorted_items=sorted(items, key=itemgetter(1), reverse=True)

sorted_items[len(sorted_items)-1]

len(sorted_items)

top30=sorted_items[:30]

sorted_items[0]

df=pd.DataFrame(top30, columns=['words','count'])

df

axes=df.plot.bar(x='words',y='count', legend=False)

text = Path('Twelve Years a Slave.txt').read_text()

text

mask_image=imageio.imread('mask_heart.png')

from wordcloud import WordCloud

wordcloud =WordCloud(width=1000,height=1000,colormap='prism',mask=mask_image,background_color='white')

wordcloud=wordcloud.generate(text)

wordcloud=wordcloud.to_file('SlaveHeart.png')

plt.imshow(wordcloud)

"""When it comes to performing serious text analysis, word visualization can only take you so far. Word clouds are a great introduction to the world of AI, but using more advanced, machine learning tools can get more from your text data.

Word clouds can be simple, fun, and insightful. Using word cloud tools, together with other text analysis tools, will both broaden and clarify your results.
"""

